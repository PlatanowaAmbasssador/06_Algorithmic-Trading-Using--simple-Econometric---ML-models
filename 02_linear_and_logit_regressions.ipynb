{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import numpy as np\n",
    "from pickle import load\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from useful_functions import *  # our own set of functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaled_Data_X = np.load('input/Scaled_Data_X.npy')\n",
    "Scaled_Data_Y = np.load('input/Scaled_Data_Y.npy')\n",
    "stock_returns = pd.read_pickle('input/stock_returns.pkl')\n",
    "df = pd.read_pickle('input/df.pkl')\n",
    "lag = load(open('input/lag.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler_X = load(open('data_objects/Scaler_X.pkl', 'rb'))\n",
    "Scaler_Y = load(open('data_objects/Scaler_Y.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(log_return):\n",
    "    if log_return > 0.001: return 'up'\n",
    "    if log_return < -0.001: return 'down'\n",
    "    if log_return >= -0.001 and log_return <= 0.001: return 'same'\n",
    "    else: return np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walk forward optimization parameters setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk-forward optimization is one of the most popular validation techniques used by financial researchers to undergo decision making for algorithmic trading. We have performed non-anchored type of Walk-forward. The process is the following:\n",
    "\n",
    "1. For each set in the hyperparameter search space, train it on the training set. Calclute the Modified Information Ratio for the training set.\n",
    "2. Validate them on the validation set. Calclute the Modified Information Ratio for the validatoin set\n",
    "3. Calculte the absolute difference between the two modified information ratio\n",
    "4. Use the set of hyperparameter where the difference is the lowest and the Modified Information Ratio on the Validation set is not 0.\n",
    "5. Predict the model using the set of hyperparameter as defined in 4. trained on the training set on the test set\n",
    "\n",
    "In case of our research problem, we set the Training Data to 250 trading days, and the Validation and Testing Data to 75 trading days each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Bars = 250 \n",
    "Validation_Bars = 75\n",
    "Testing_Bars = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges = list(range(Training_Bars, len(Scaled_Data_Y) - Testing_Bars, Validation_Bars))\n",
    "len(ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tune two hyperparameters:\n",
    "- `alpha` - regularization term used in elastic net regularization, \n",
    "- `l1_ratio` - weight of L1 (lasso) in elastic net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = [np.power(10., i) for i in range (-5, 6)]  # regularization terms (hyperparameter search space)\n",
    "l1_ratio = [0, 0.25, 0.5, 0.75, 1] # L1 regularizationweight (hyperparameter search space)\n",
    "\n",
    "\n",
    "config = [\n",
    "    {\n",
    "    'alpha' : a,\n",
    "    'l1_ratio': lr\n",
    "    }\n",
    "    for a in alpha\n",
    "    for lr in l1_ratio\n",
    "]\n",
    "\n",
    "len(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_get_label = np.vectorize(get_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because linear regression is a model for numerical output, after making predictions we transform them to classes the same way we did when we were calculating values of our label (see `get_label` function in `useful_functions.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Model Configuration Is: {'alpha': 1e-05, 'l1_ratio': 0.25}\n",
      "Training IR2: [0.04948973],           Validation IR2: [0.77190656],           Testing IR2: [277.16034084]\n",
      "ID_0 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.01, 'l1_ratio': 0.5}\n",
      "Training IR2: [2.98637954],           Validation IR2: [74.13220131],           Testing IR2: [15.89342985]\n",
      "ID_1 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.01, 'l1_ratio': 0}\n",
      "Training IR2: [7.20774328],           Validation IR2: [7.17708415],           Testing IR2: [4.14902269]\n",
      "ID_2 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.001, 'l1_ratio': 1}\n",
      "Training IR2: [6.59701424],           Validation IR2: [6.70309997],           Testing IR2: [0.24354051]\n",
      "ID_3 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.001, 'l1_ratio': 0}\n",
      "Training IR2: [10.29090622],           Validation IR2: [0.24354051],           Testing IR2: [0]\n",
      "ID_4 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.0001, 'l1_ratio': 0.5}\n",
      "Training IR2: [9.00036858],           Validation IR2: [0],           Testing IR2: [0]\n",
      "ID_5 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.001, 'l1_ratio': 0}\n",
      "Training IR2: [2.63324416],           Validation IR2: [0],           Testing IR2: [0.21306]\n",
      "ID_6 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.001, 'l1_ratio': 1}\n",
      "Training IR2: [0],           Validation IR2: [0.00055903],           Testing IR2: [14.13712691]\n",
      "ID_7 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1e-05, 'l1_ratio': 0}\n",
      "Training IR2: [0],           Validation IR2: [17.31719343],           Testing IR2: [0.38665319]\n",
      "ID_8 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.1, 'l1_ratio': 0.25}\n",
      "Training IR2: [0.00147749],           Validation IR2: [2.49493216],           Testing IR2: [173.90377797]\n",
      "ID_9 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.1, 'l1_ratio': 0.25}\n",
      "Training IR2: [0.89103173],           Validation IR2: [173.90377797],           Testing IR2: [6.1356965]\n",
      "ID_10 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1e-05, 'l1_ratio': 0}\n",
      "Training IR2: [12.03646899],           Validation IR2: [12.36499303],           Testing IR2: [2.4618739]\n",
      "ID_11 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1e-05, 'l1_ratio': 1}\n",
      "Training IR2: [10.09390114],           Validation IR2: [1.9628524],           Testing IR2: [0.00048675]\n",
      "ID_12 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.1, 'l1_ratio': 0.25}\n",
      "Training IR2: [20.19702064],           Validation IR2: [0.23461782],           Testing IR2: [9.09017119]\n",
      "ID_13 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.01, 'l1_ratio': 0}\n",
      "Training IR2: [1.9750967],           Validation IR2: [3.36324532],           Testing IR2: [4.83891214]\n",
      "ID_14 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.0001, 'l1_ratio': 0}\n",
      "Training IR2: [3.50133762],           Validation IR2: [15.40540676],           Testing IR2: [0]\n",
      "ID_15 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.001, 'l1_ratio': 0.75}\n",
      "Training IR2: [6.90546938],           Validation IR2: [0],           Testing IR2: [1.4437893]\n",
      "ID_16 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.001, 'l1_ratio': 0}\n",
      "Training IR2: [0.04802328],           Validation IR2: [0.04315631],           Testing IR2: [23.82154468]\n",
      "ID_17 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1e-05, 'l1_ratio': 0}\n",
      "Training IR2: [0.00031847],           Validation IR2: [44.84509146],           Testing IR2: [230.67724932]\n",
      "ID_18 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.001, 'l1_ratio': 0}\n",
      "Training IR2: [0.02812938],           Validation IR2: [111.72210436],           Testing IR2: [0]\n",
      "ID_19 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.01, 'l1_ratio': 0}\n",
      "Training IR2: [23.19367635],           Validation IR2: [0],           Testing IR2: [884.53313538]\n",
      "ID_20 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.001, 'l1_ratio': 1}\n",
      "Training IR2: [0.30303992],           Validation IR2: [130.58344411],           Testing IR2: [0.96057181]\n",
      "ID_21 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.01, 'l1_ratio': 0.5}\n",
      "Training IR2: [6.13346522],           Validation IR2: [0.27426716],           Testing IR2: [0.54287871]\n",
      "ID_22 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.1, 'l1_ratio': 0.25}\n",
      "Training IR2: [1.93293456],           Validation IR2: [0.54287871],           Testing IR2: [5.1766659]\n",
      "ID_23 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.001, 'l1_ratio': 1}\n",
      "Training IR2: [5.80952816],           Validation IR2: [5.49753022],           Testing IR2: [5.81578277]\n",
      "ID_24 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.01, 'l1_ratio': 1}\n",
      "Training IR2: [2.38602713],           Validation IR2: [1.19398188],           Testing IR2: [18.67719175]\n",
      "ID_25 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.1, 'l1_ratio': 0.25}\n",
      "Training IR2: [1.01796976],           Validation IR2: [13.95381082],           Testing IR2: [0]\n",
      "ID_26 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.1, 'l1_ratio': 0}\n",
      "Training IR2: [5.2840746],           Validation IR2: [0],           Testing IR2: [2.6458246]\n",
      "ID_27 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.01, 'l1_ratio': 0}\n",
      "Training IR2: [0.02413201],           Validation IR2: [0.05709184],           Testing IR2: [0]\n",
      "ID_28 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.1, 'l1_ratio': 0.25}\n",
      "Training IR2: [0.02136522],           Validation IR2: [0],           Testing IR2: [98.30454246]\n",
      "ID_29 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.0001, 'l1_ratio': 0}\n",
      "Training IR2: [0],           Validation IR2: [98.30454246],           Testing IR2: [111.53277556]\n",
      "ID_30 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.001, 'l1_ratio': 0}\n",
      "Training IR2: [0.0914775],           Validation IR2: [53.56204377],           Testing IR2: [0.]\n",
      "ID_31 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1e-05, 'l1_ratio': 0}\n",
      "Training IR2: [0.49520944],           Validation IR2: [0],           Testing IR2: [4.58985288]\n",
      "ID_32 - DONE\n"
     ]
    }
   ],
   "source": [
    "RF = np.random.RandomState(seed=4015)\n",
    "\n",
    "ranges = list(range(Training_Bars, len(Scaled_Data_Y) - Testing_Bars, Validation_Bars))\n",
    "\n",
    "df_all_score = {}\n",
    "\n",
    "ALL_MODEL_PREDICTIONS = np.zeros((0,1)).flatten()\n",
    "for i in range(0, len(ranges)):\n",
    "\n",
    "    train_X, train_y, train_stock_returns = Scaled_Data_X[ranges[i]-Training_Bars:ranges[i]], Scaled_Data_Y[ranges[i]-Training_Bars:ranges[i]], stock_returns[ranges[i]-Training_Bars:ranges[i]]\n",
    "    val_X, val_Y, val_stock_returns = Scaled_Data_X[ranges[i]:ranges[i]+Validation_Bars], Scaled_Data_Y[ranges[i]:ranges[i]+Validation_Bars], stock_returns[ranges[i]:ranges[i]+Validation_Bars]\n",
    "    test_X, test_y, test_stock_returns = Scaled_Data_X[ranges[i]+Validation_Bars:ranges[i]+Validation_Bars+Testing_Bars], Scaled_Data_Y[ranges[i]+Validation_Bars:ranges[i]+Validation_Bars+Testing_Bars], stock_returns[ranges[i]+Validation_Bars:ranges[i]+Validation_Bars+Testing_Bars]\n",
    "    \n",
    "    training_IR2 = []\n",
    "    validation_IR2 = []\n",
    "    testing_IR2 = []\n",
    "    config_all = []\n",
    "    for num, cfg in enumerate(config):\n",
    "        model_cfg = ElasticNet(alpha=cfg['alpha'],\n",
    "                               l1_ratio=cfg['l1_ratio'])\n",
    "        \n",
    "        model_cfg.fit(train_X, train_y)\n",
    "\n",
    "        cfg_IR2_train = get_eqline_IR2(train_stock_returns, v_get_label(model_cfg.predict(train_X)).astype(object))\n",
    "        cfg_IR2_val = get_eqline_IR2(val_stock_returns, v_get_label(model_cfg.predict(val_X)).astype(object))\n",
    "        cfg_IR2_test = get_eqline_IR2(test_stock_returns, v_get_label(model_cfg.predict(test_X)).astype(object))\n",
    "\n",
    "        training_IR2.append(cfg_IR2_train)\n",
    "        validation_IR2.append(cfg_IR2_val)\n",
    "        testing_IR2.append(cfg_IR2_test)\n",
    "\n",
    "        config_all.append(cfg)\n",
    "    \n",
    "\n",
    "    df_finding_the_best_configuration = pd.DataFrame(\n",
    "        data = {\n",
    "            'Config': config_all,\n",
    "            'Training IR2': training_IR2,\n",
    "            'Validation IR2': validation_IR2,\n",
    "            'Testing IR2': testing_IR2\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df_all_score[f'id_{i}'] = df_finding_the_best_configuration\n",
    "\n",
    "    df_finding_the_best_configuration['custom_score'] =  abs(df_finding_the_best_configuration['Validation IR2'] - df_finding_the_best_configuration['Training IR2'])\n",
    "    df_finding_the_best_configuration['custom_score'] = np.where(df_finding_the_best_configuration['Validation IR2']==0, np.nan, df_finding_the_best_configuration['custom_score'])\n",
    "\n",
    "    try:    \n",
    "        best_config = df_finding_the_best_configuration.loc[df_finding_the_best_configuration['custom_score'].idxmin()]['Config']\n",
    "    except:\n",
    "        best_config = df_finding_the_best_configuration.loc[df_finding_the_best_configuration['Training IR2'].idxmax()]['Config']    \n",
    "\n",
    "    print(f'The Best Model Configuration Is: {best_config}')\n",
    "    print(f\"Training IR2: {df_all_score[f'id_{i}'][df_all_score[f'id_{i}']['Config']==best_config]['Training IR2'].values}, \\\n",
    "          Validation IR2: {df_all_score[f'id_{i}'][df_all_score[f'id_{i}']['Config']==best_config]['Validation IR2'].values}, \\\n",
    "          Testing IR2: {df_all_score[f'id_{i}'][df_all_score[f'id_{i}']['Config']==best_config]['Testing IR2'].values}\")\n",
    "\n",
    "    # Fit the model on the combined data Train and Val \n",
    "    combined_train_val_X = np.concatenate([train_X, val_X]) \n",
    "    combined_train_val_Y = np.concatenate([train_y, val_Y]) \n",
    "    \n",
    "    model = ElasticNet(alpha=best_config['alpha'],\n",
    "                       l1_ratio=best_config['l1_ratio'])\n",
    "    \n",
    "    model.fit(combined_train_val_X, combined_train_val_Y)\n",
    "\n",
    "    PREDICTIONS = model.predict(test_X)\n",
    "    ALL_MODEL_PREDICTIONS = np.concatenate((ALL_MODEL_PREDICTIONS, PREDICTIONS))\n",
    "\n",
    "    print(f'ID_{i} - DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id0 = df_all_score['id_1']\n",
    "id0_condig_df = pd.json_normalize(id0['Config'])\n",
    "id0_df = pd.concat([id0, id0_condig_df], axis=1).drop(['Config'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_id0_df = id0_df.sort_values(by='custom_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save our predictions for laster analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos_linear_regression = pd.Series(v_get_label(ALL_MODEL_PREDICTIONS).astype(object),\n",
    "                                       index=df[Training_Bars+Validation_Bars+lag:Training_Bars+Validation_Bars+lag+len(ALL_MODEL_PREDICTIONS)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos_linear_regression.to_pickle('output/lin_reg.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tune three hyperparameters:\n",
    "- `C` - inverse of regularization term used in elastic net regularization, \n",
    "- `l1_ratio` - weight of L1 (lasso) in elastic net,\n",
    "- `multi_class` - option to fit the logit model, for `ovr` one-versus-rest approach is applied, for `multinomial` the loss minimised is the multinomial loss fit across the entire probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = [np.power(10., i) for i in range (-5, 6)]  # regularization terms (hyperparameter search space)\n",
    "l1_ratio = [0, 0.25, 0.5, 0.75, 1] # L1 regularizationweight (hyperparameter search space)\n",
    "penalty = ['elasticnet']\n",
    "solver = ['saga']\n",
    "multi_class = ['multinomial', 'ovr']\n",
    "\n",
    "\n",
    "config = [\n",
    "    {\n",
    "    'alpha' : a,\n",
    "    'l1_ratio': lr,\n",
    "    'penalty': pen,\n",
    "    'solver': solv,\n",
    "    'multi_class': mtc\n",
    "    }\n",
    "    for a in alpha\n",
    "    for lr in l1_ratio\n",
    "    for pen in penalty\n",
    "    for solv in solver\n",
    "    for mtc in multi_class\n",
    "]\n",
    "\n",
    "len(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Model Configuration Is: {'alpha': 10000.0, 'l1_ratio': 0, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [0.00530282],           Validation IR2: [1.76404714],           Testing IR2: [100.24578774]\n",
      "ID_0 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 1, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [10.92011257],           Validation IR2: [68.01075106],           Testing IR2: [1.06148676]\n",
      "ID_1 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1.0, 'l1_ratio': 0.5, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [36.8943877],           Validation IR2: [36.98389035],           Testing IR2: [11.36442378]\n",
      "ID_2 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 100.0, 'l1_ratio': 0.25, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [6.27997788],           Validation IR2: [6.68375054],           Testing IR2: [0.24354051]\n",
      "ID_3 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1000.0, 'l1_ratio': 0, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [10.23147456],           Validation IR2: [0.24354051],           Testing IR2: [0]\n",
      "ID_4 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0.5, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [15.45183337],           Validation IR2: [0],           Testing IR2: [0]\n",
      "ID_5 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 0.1, 'l1_ratio': 0.25, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [10.07694069],           Validation IR2: [0],           Testing IR2: [110.49388002]\n",
      "ID_6 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0.75, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [0.],           Validation IR2: [0.00669263],           Testing IR2: [0.]\n",
      "ID_7 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0.25, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [0.86464095],           Validation IR2: [0.85624289],           Testing IR2: [1.45747697]\n",
      "ID_8 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1e-05, 'l1_ratio': 0, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [0.01320439],           Validation IR2: [0.02236407],           Testing IR2: [31.97015907]\n",
      "ID_9 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1.0, 'l1_ratio': 0, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [1.3506658],           Validation IR2: [44.99352723],           Testing IR2: [104.47939223]\n",
      "ID_10 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 100.0, 'l1_ratio': 0, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [7.15753783],           Validation IR2: [5.41616961],           Testing IR2: [0.16037806]\n",
      "ID_11 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [7.80860349],           Validation IR2: [7.42671756],           Testing IR2: [0.41525454]\n",
      "ID_12 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0.5, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [6.05139635],           Validation IR2: [0.79518397],           Testing IR2: [0.]\n",
      "ID_13 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0.75, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [6.40480343],           Validation IR2: [6.67643627],           Testing IR2: [5.78971225]\n",
      "ID_14 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0.75, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [2.19216757],           Validation IR2: [0.6992123],           Testing IR2: [0]\n",
      "ID_15 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1.0, 'l1_ratio': 0, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [19.89772046],           Validation IR2: [0],           Testing IR2: [0.]\n",
      "ID_16 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [0.],           Validation IR2: [0.00578795],           Testing IR2: [0.]\n",
      "ID_17 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1.0, 'l1_ratio': 0.25, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [0.],           Validation IR2: [0.00189674],           Testing IR2: [237.18951529]\n",
      "ID_18 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [0.],           Validation IR2: [70.1003431],           Testing IR2: [0]\n",
      "ID_19 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1.0, 'l1_ratio': 0.25, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [40.57678174],           Validation IR2: [0],           Testing IR2: [88.0111765]\n",
      "ID_20 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0.25, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [0.],           Validation IR2: [50.43692568],           Testing IR2: [0.]\n",
      "ID_21 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1.0, 'l1_ratio': 1, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [0.58831131],           Validation IR2: [0.70534746],           Testing IR2: [0.27457814]\n",
      "ID_22 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 1, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [1.75925416],           Validation IR2: [1.53353441],           Testing IR2: [7.01058087]\n",
      "ID_23 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 1, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [6.79079459],           Validation IR2: [7.42012328],           Testing IR2: [0.43496721]\n",
      "ID_24 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1000.0, 'l1_ratio': 0, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [0.38728497],           Validation IR2: [1.28443359],           Testing IR2: [77.55258806]\n",
      "ID_25 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0.5, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [0.00032333],           Validation IR2: [4.45585388],           Testing IR2: [0]\n",
      "ID_26 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1000.0, 'l1_ratio': 0, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [8.51059945],           Validation IR2: [0],           Testing IR2: [12.92689492]\n",
      "ID_27 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0.75, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'ovr'}\n",
      "Training IR2: [0.93941772],           Validation IR2: [0.92524443],           Testing IR2: [0]\n",
      "ID_28 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1.0, 'l1_ratio': 0.25, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [0.06958156],           Validation IR2: [0.0213759],           Testing IR2: [7.51282101]\n",
      "ID_29 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0.75, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [0.],           Validation IR2: [0.27097859],           Testing IR2: [0.]\n",
      "ID_30 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 1.0, 'l1_ratio': 0, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [0.39539839],           Validation IR2: [8.14528705],           Testing IR2: [0.]\n",
      "ID_31 - DONE\n",
      "The Best Model Configuration Is: {'alpha': 10.0, 'l1_ratio': 0.75, 'penalty': 'elasticnet', 'solver': 'saga', 'multi_class': 'multinomial'}\n",
      "Training IR2: [0.07267283],           Validation IR2: [0.33381251],           Testing IR2: [6.23116156]\n",
      "ID_32 - DONE\n"
     ]
    }
   ],
   "source": [
    "RF = np.random.RandomState(seed=4015)\n",
    "\n",
    "ranges = list(range(Training_Bars, len(Scaled_Data_Y) - Testing_Bars, Validation_Bars))\n",
    "\n",
    "df_all_score = {}\n",
    "\n",
    "ALL_MODEL_PREDICTIONS = np.zeros((0,1)).flatten()\n",
    "for i in range(0, len(ranges)):\n",
    "\n",
    "    train_X, train_y, train_stock_returns = Scaled_Data_X[ranges[i]-Training_Bars:ranges[i]], Scaled_Data_Y[ranges[i]-Training_Bars:ranges[i]], stock_returns[ranges[i]-Training_Bars:ranges[i]]\n",
    "    val_X, val_Y, val_stock_returns = Scaled_Data_X[ranges[i]:ranges[i]+Validation_Bars], Scaled_Data_Y[ranges[i]:ranges[i]+Validation_Bars], stock_returns[ranges[i]:ranges[i]+Validation_Bars]\n",
    "    test_X, test_y, test_stock_returns = Scaled_Data_X[ranges[i]+Validation_Bars:ranges[i]+Validation_Bars+Testing_Bars], Scaled_Data_Y[ranges[i]+Validation_Bars:ranges[i]+Validation_Bars+Testing_Bars], stock_returns[ranges[i]+Validation_Bars:ranges[i]+Validation_Bars+Testing_Bars]\n",
    "    \n",
    "    training_IR2 = []\n",
    "    validation_IR2 = []\n",
    "    testing_IR2 = []\n",
    "    config_all = []\n",
    "    for num, cfg in enumerate(config):\n",
    "        model_cfg = LogisticRegression(penalty=cfg['penalty'],\n",
    "                                       C=1/cfg['alpha'],\n",
    "                                       l1_ratio=cfg['l1_ratio'],\n",
    "                                       solver=cfg['solver'],\n",
    "                                       multi_class=cfg['multi_class'],\n",
    "                                       random_state=RF)\n",
    "        \n",
    "        model_cfg.fit(train_X, train_y)\n",
    "\n",
    "        cfg_IR2_train = get_eqline_IR2(train_stock_returns, Scaler_Y.inverse_transform(model_cfg.predict(train_X)))\n",
    "        cfg_IR2_val = get_eqline_IR2(val_stock_returns, Scaler_Y.inverse_transform(model_cfg.predict(val_X)))\n",
    "        cfg_IR2_test = get_eqline_IR2(test_stock_returns, Scaler_Y.inverse_transform(model_cfg.predict(test_X)))\n",
    "        \n",
    "        training_IR2.append(cfg_IR2_train)\n",
    "        validation_IR2.append(cfg_IR2_val)\n",
    "        testing_IR2.append(cfg_IR2_test)\n",
    "\n",
    "        config_all.append(cfg)\n",
    "    \n",
    "\n",
    "    df_finding_the_best_configuration = pd.DataFrame(\n",
    "        data = {\n",
    "            'Config': config_all,\n",
    "            'Training IR2': training_IR2,\n",
    "            'Validation IR2': validation_IR2,\n",
    "            'Testing IR2': testing_IR2\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df_all_score[f'id_{i}'] = df_finding_the_best_configuration\n",
    "\n",
    "    df_finding_the_best_configuration['custom_score'] =  abs(df_finding_the_best_configuration['Validation IR2'] - df_finding_the_best_configuration['Training IR2'])\n",
    "    df_finding_the_best_configuration['custom_score'] = np.where(df_finding_the_best_configuration['Validation IR2']==0, np.nan, df_finding_the_best_configuration['custom_score'])\n",
    "\n",
    "    try:    \n",
    "        best_config = df_finding_the_best_configuration.loc[df_finding_the_best_configuration['custom_score'].idxmin()]['Config']\n",
    "    except:\n",
    "        best_config = df_finding_the_best_configuration.loc[df_finding_the_best_configuration['Training IR2'].idxmax()]['Config']    \n",
    "\n",
    "    print(f'The Best Model Configuration Is: {best_config}')\n",
    "    print(f\"Training IR2: {df_all_score[f'id_{i}'][df_all_score[f'id_{i}']['Config']==best_config]['Training IR2'].values}, \\\n",
    "          Validation IR2: {df_all_score[f'id_{i}'][df_all_score[f'id_{i}']['Config']==best_config]['Validation IR2'].values}, \\\n",
    "          Testing IR2: {df_all_score[f'id_{i}'][df_all_score[f'id_{i}']['Config']==best_config]['Testing IR2'].values}\")\n",
    "\n",
    "    # Fit the model on the combined data Train and Val \n",
    "    combined_train_val_X = np.concatenate([train_X, val_X]) \n",
    "    combined_train_val_Y = np.concatenate([train_y, val_Y]) \n",
    "    \n",
    "    model = LogisticRegression(penalty=best_config['penalty'],\n",
    "                               C=1/best_config['alpha'],\n",
    "                               l1_ratio=best_config['l1_ratio'],\n",
    "                               solver=best_config['solver'],\n",
    "                               multi_class=best_config['multi_class'],\n",
    "                               random_state=RF)\n",
    "    \n",
    "    model.fit(combined_train_val_X, combined_train_val_Y)\n",
    "\n",
    "    PREDICTIONS = model.predict(test_X)\n",
    "    ALL_MODEL_PREDICTIONS = np.concatenate((ALL_MODEL_PREDICTIONS, PREDICTIONS))\n",
    "\n",
    "    print(f'ID_{i} - DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save our data for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos_logit_regression = pd.Series(Scaler_Y.inverse_transform(ALL_MODEL_PREDICTIONS.astype(int)),\n",
    "                                      index=df[Training_Bars+Validation_Bars+lag:Training_Bars+Validation_Bars+lag+len(ALL_MODEL_PREDICTIONS)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos_logit_regression.to_pickle('output/log_reg.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlf1_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
