{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import numpy as np\n",
    "from pickle import load\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from useful_functions import *  # our own set of functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaled_Data_X = np.load('input/Scaled_Data_X.npy')\n",
    "Scaled_Data_Y = np.load('input/Scaled_Data_Y.npy')\n",
    "stock_returns = pd.read_pickle('input/stock_returns.pkl')\n",
    "df = pd.read_pickle('input/df.pkl')\n",
    "lag = load(open('input/lag.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler_X = load(open('data_objects/Scaler_X.pkl', 'rb'))\n",
    "Scaler_Y = load(open('data_objects/Scaler_Y.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk-Forward Optimizatoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk-forward optimization is one of the most popular validation techniques used by financial researchers to undergo decision making for algorithmic trading. We have performed non-anchored type of Walk-forward. The process is the following:\n",
    "\n",
    "1. For each set in the hyperparameter search space, train it on the training set. Calclute the Modified Information Ratio for the training set.\n",
    "2. Validate them on the validation set. Calclute the Modified Information Ratio for the validatoin set\n",
    "3. Calculte the absolute difference between the two modified information ratio\n",
    "4. Use the set of hyperparameter where the difference is the lowest and the Modified Information Ratio on the Validation set is not 0.\n",
    "5. Predict the model using the set of hyperparameter as defined in 4. trained on the training set on the test set\n",
    "\n",
    "In case of our research problem, we set the Training Data to 250 trading days, and the Validation and Testing Data to 75 trading days each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Bars = 250 \n",
    "Validation_Bars = 75\n",
    "Testing_Bars = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is not a very computationally expensive model compared to others for example Neural Networks, we decided to perform Grid Search for tuning the hyperparameters. The hyperparameter search space is selected after deep analysis. Multiple hyperparamter tunning processes were conducted before arriving to this search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [300]\n",
    "criterion = ['entropy']\n",
    "max_depth = [5, 8] # 2\n",
    "min_samples_split = [30, 60]\n",
    "min_samples_leaf = [20, 40]\n",
    "min_weight_fraction_leaf = [0]\n",
    "max_features = [60]\n",
    "max_leaf_nodes = [None]\n",
    "min_impurity_decrease = [0.0025, 0.0015]\n",
    "bootstrap = [False] # Was True\n",
    "oob_score = [False]\n",
    "n_jobs = [-1]\n",
    "\n",
    "digit = 8\n",
    "\n",
    "config = [\n",
    "    {\n",
    "    'n_estimators': ne,\n",
    "    'criterion': c,\n",
    "    'max_depth': md,\n",
    "    'min_samples_split': mss,\n",
    "    'min_samples_leaf': msl,\n",
    "    'min_weight_fraction_leaf': mwfl,\n",
    "    'max_features': mf,\n",
    "    'max_leaf_nodes': mln,\n",
    "    'min_impurity_decrease': mid,\n",
    "    'bootstrap': b,\n",
    "    'oob_score': os,\n",
    "    'n_jobs': nj,\n",
    "    }\n",
    "    for ne in n_estimators\n",
    "    for c in criterion\n",
    "    for md in max_depth\n",
    "    for mss in min_samples_split\n",
    "    for msl in min_samples_leaf\n",
    "    for mwfl in min_weight_fraction_leaf\n",
    "    for mf in max_features\n",
    "    for mln in max_leaf_nodes\n",
    "    for mid in min_impurity_decrease\n",
    "    for b in bootstrap\n",
    "    for os in oob_score\n",
    "    for nj in n_jobs\n",
    "]\n",
    "\n",
    "len(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Seed Is: 7\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 60, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.94805931],           Validation IR2: [55.86990629],           Testing IR2: [158.53768724]\n",
      "158.5376872399038\n",
      "ID_0 - DONE\n",
      "The Random Seed Is: 13\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 60, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [6.28124631],           Validation IR2: [5.46496481],           Testing IR2: [32.83931231]\n",
      "32.83931231469978\n",
      "ID_1 - DONE\n",
      "The Random Seed Is: 16\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 60, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [14.85770368],           Validation IR2: [0.01399176],           Testing IR2: [0.58245069]\n",
      "0.5824506940830254\n",
      "ID_2 - DONE\n",
      "The Random Seed Is: 3\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 30, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [7.47368809],           Validation IR2: [0.0008032],           Testing IR2: [22.63595786]\n",
      "22.635957862474672\n",
      "ID_3 - DONE\n",
      "The Random Seed Is: 11\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 60, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [7.9778669],           Validation IR2: [1.8127041],           Testing IR2: [0.01067316]\n",
      "0.010673159717323452\n",
      "ID_4 - DONE\n",
      "The Random Seed Is: 8\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 30, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [1.86777089],           Validation IR2: [0.10607892],           Testing IR2: [0]\n",
      "0\n",
      "ID_5 - DONE\n",
      "The Random Seed Is: 17\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.72908526],           Validation IR2: [0.69969001],           Testing IR2: [0.]\n",
      "0\n",
      "ID_6 - DONE\n",
      "The Random Seed Is: 17\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.],           Validation IR2: [0.00019981],           Testing IR2: [3.32162644]\n",
      "3.3216264394459265\n",
      "ID_7 - DONE\n",
      "The Random Seed Is: 17\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.],           Validation IR2: [0.22906091],           Testing IR2: [142.74648217]\n",
      "142.74648217464863\n",
      "ID_8 - DONE\n",
      "The Random Seed Is: 17\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.58758742],           Validation IR2: [0.71832414],           Testing IR2: [21.47020826]\n",
      "21.470208262675364\n",
      "ID_9 - DONE\n",
      "The Random Seed Is: 23\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 60, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [2.04755288],           Validation IR2: [128.17441154],           Testing IR2: [119.70484895]\n",
      "119.7048489534065\n",
      "ID_10 - DONE\n",
      "The Random Seed Is: 25\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 60, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [9.80580272],           Validation IR2: [7.08935107],           Testing IR2: [3.41658767]\n",
      "3.416587667710645\n",
      "ID_11 - DONE\n",
      "The Random Seed Is: 18\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 60, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [2.71984841],           Validation IR2: [3.22442804],           Testing IR2: [7.97228489]\n",
      "7.97228489020502\n",
      "ID_12 - DONE\n",
      "The Random Seed Is: 20\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 60, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [20.19364911],           Validation IR2: [8.5463529],           Testing IR2: [27.51315326]\n",
      "27.513153263844895\n",
      "ID_13 - DONE\n",
      "The Random Seed Is: 27\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 60, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [22.9270185],           Validation IR2: [19.71358827],           Testing IR2: [17.2103515]\n",
      "17.210351501168404\n",
      "ID_14 - DONE\n",
      "The Random Seed Is: 26\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [8.34361667],           Validation IR2: [12.04868276],           Testing IR2: [0]\n",
      "0\n",
      "ID_15 - DONE\n",
      "The Random Seed Is: 24\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [9.33634056],           Validation IR2: [0],           Testing IR2: [5.11076188]\n",
      "5.110761883458501\n",
      "ID_16 - DONE\n",
      "The Random Seed Is: 30\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 60, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.00036282],           Validation IR2: [0.11715714],           Testing IR2: [45.68201798]\n",
      "45.682017976002065\n",
      "ID_17 - DONE\n",
      "The Random Seed Is: 28\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.12417002],           Validation IR2: [17.6927443],           Testing IR2: [167.84873247]\n",
      "167.84873246820325\n",
      "ID_18 - DONE\n",
      "The Random Seed Is: 20\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 30, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.],           Validation IR2: [217.78417693],           Testing IR2: [0.]\n",
      "0\n",
      "ID_19 - DONE\n",
      "The Random Seed Is: 23\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 30, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [25.26960896],           Validation IR2: [0],           Testing IR2: [783.14320799]\n",
      "783.1432079922394\n",
      "ID_20 - DONE\n",
      "The Random Seed Is: 32\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.14033554],           Validation IR2: [13.5149722],           Testing IR2: [0.47680542]\n",
      "0.4768054169653593\n",
      "ID_21 - DONE\n",
      "The Random Seed Is: 33\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.02780775],           Validation IR2: [0.10362604],           Testing IR2: [13.40181856]\n",
      "13.401818558353497\n",
      "ID_22 - DONE\n",
      "The Random Seed Is: 24\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 30, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.87140914],           Validation IR2: [0.84982539],           Testing IR2: [0.00952433]\n",
      "0.009524332838447369\n",
      "ID_23 - DONE\n",
      "The Random Seed Is: 33\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [7.68349012],           Validation IR2: [0.0905906],           Testing IR2: [0.74873508]\n",
      "0.7487350753130423\n",
      "ID_24 - DONE\n",
      "The Random Seed Is: 31\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 60, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.06545287],           Validation IR2: [0.09608547],           Testing IR2: [2.82435721]\n",
      "2.824357207137168\n",
      "ID_25 - DONE\n",
      "The Random Seed Is: 35\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0015, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.02961748],           Validation IR2: [11.60199167],           Testing IR2: [0]\n",
      "0\n",
      "ID_26 - DONE\n",
      "The Random Seed Is: 37\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [3.7511235],           Validation IR2: [0],           Testing IR2: [35.84639387]\n",
      "35.84639386703465\n",
      "ID_27 - DONE\n",
      "The Random Seed Is: 28\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 30, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.92131189],           Validation IR2: [0.63862301],           Testing IR2: [0]\n",
      "0\n",
      "ID_28 - DONE\n",
      "The Random Seed Is: 31\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 30, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [6.09944949],           Validation IR2: [0],           Testing IR2: [58.80874306]\n",
      "58.80874305521073\n",
      "ID_29 - DONE\n",
      "The Random Seed Is: 32\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 30, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.],           Validation IR2: [0.93334894],           Testing IR2: [0]\n",
      "0\n",
      "ID_30 - DONE\n",
      "The Random Seed Is: 43\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 60, 'min_samples_leaf': 20, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.31211013],           Validation IR2: [185.20385683],           Testing IR2: [0]\n",
      "0\n",
      "ID_31 - DONE\n",
      "The Random Seed Is: 42\n",
      "The Best Model Configuration Is: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 40, 'min_weight_fraction_leaf': 0, 'max_features': 60, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0025, 'bootstrap': False, 'oob_score': False, 'n_jobs': -1}\n",
      "Training IR2: [0.8189679],           Validation IR2: [0.02205716],           Testing IR2: [14.90702812]\n",
      "14.9070281161555\n",
      "ID_32 - DONE\n"
     ]
    }
   ],
   "source": [
    "ranges = list(range(Training_Bars, len(Scaled_Data_Y) - Testing_Bars, Validation_Bars))\n",
    "\n",
    "df_all_score = {}\n",
    "\n",
    "ALL_MODEL_PREDICTIONS = np.zeros((0,1)).flatten()\n",
    "for i in range(0, len(ranges)): \n",
    "\n",
    "    train_X, train_y, train_stock_returns = Scaled_Data_X[ranges[i]-Training_Bars:ranges[i]], Scaled_Data_Y[ranges[i]-Training_Bars:ranges[i]], stock_returns[ranges[i]-Training_Bars:ranges[i]]\n",
    "    val_X, val_Y, val_stock_returns = Scaled_Data_X[ranges[i]:ranges[i]+Validation_Bars], Scaled_Data_Y[ranges[i]:ranges[i]+Validation_Bars], stock_returns[ranges[i]:ranges[i]+Validation_Bars]\n",
    "    test_X, test_y, test_stock_returns = Scaled_Data_X[ranges[i]+Validation_Bars:ranges[i]+Validation_Bars+Testing_Bars], Scaled_Data_Y[ranges[i]+Validation_Bars:ranges[i]+Validation_Bars+Testing_Bars], stock_returns[ranges[i]+Validation_Bars:ranges[i]+Validation_Bars+Testing_Bars]\n",
    "    \n",
    "    training_IR2 = []\n",
    "    validation_IR2 = []\n",
    "    testing_IR2 = []\n",
    "    config_all = []\n",
    "    for num, cfg in enumerate(config):\n",
    "        model_cfg = RandomForestClassifier(\n",
    "                                    n_estimators = cfg['n_estimators'],\n",
    "                                    criterion = cfg['criterion'],\n",
    "                                    max_depth = cfg['max_depth'],\n",
    "                                    min_samples_split = cfg['min_samples_split'],\n",
    "                                    min_samples_leaf = cfg['min_samples_leaf'],\n",
    "                                    min_weight_fraction_leaf = cfg['min_weight_fraction_leaf'],\n",
    "                                    max_features = cfg['max_features'],\n",
    "                                    max_leaf_nodes = cfg['max_leaf_nodes'],\n",
    "                                    min_impurity_decrease = cfg['min_impurity_decrease'],\n",
    "                                    bootstrap = cfg['bootstrap'],\n",
    "                                    oob_score = cfg['oob_score'],\n",
    "                                    n_jobs = cfg['n_jobs'],\n",
    "                                    random_state = i+num+digit\n",
    "                                    )\n",
    "        \n",
    "        model_cfg.fit(train_X, train_y)\n",
    "\n",
    "        cfg_IR2_train = get_eqline_IR2(train_stock_returns, Scaler_Y.inverse_transform(model_cfg.predict(train_X)))\n",
    "        cfg_IR2_val = get_eqline_IR2(val_stock_returns, Scaler_Y.inverse_transform(model_cfg.predict(val_X)))\n",
    "        cfg_IR2_test = get_eqline_IR2(test_stock_returns, Scaler_Y.inverse_transform(model_cfg.predict(test_X)))\n",
    "\n",
    "        training_IR2.append(cfg_IR2_train)\n",
    "        validation_IR2.append(cfg_IR2_val)\n",
    "        testing_IR2.append(cfg_IR2_test)\n",
    "\n",
    "        config_all.append(cfg)\n",
    "    \n",
    "\n",
    "    df_finding_the_best_configuration = pd.DataFrame(\n",
    "        data = {\n",
    "            'Config': config_all,\n",
    "            'Training IR2': training_IR2,\n",
    "            'Validation IR2': validation_IR2,\n",
    "            'Testing IR2': testing_IR2\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df_all_score[f'id_{i}'] = df_finding_the_best_configuration\n",
    "\n",
    "    df_finding_the_best_configuration['custom_score'] =  abs(df_finding_the_best_configuration['Validation IR2'] - df_finding_the_best_configuration['Training IR2'])\n",
    "    df_finding_the_best_configuration['custom_score'] = np.where(df_finding_the_best_configuration['Validation IR2']==0, np.nan, df_finding_the_best_configuration['custom_score'])\n",
    "\n",
    "    try:    \n",
    "        best_config = df_finding_the_best_configuration.loc[df_finding_the_best_configuration['custom_score'].idxmin()]['Config']\n",
    "        best_config_index = df_finding_the_best_configuration['custom_score'].idxmin()\n",
    "    except:\n",
    "        best_config = df_finding_the_best_configuration.loc[df_finding_the_best_configuration['Training IR2'].idxmax()]['Config']  \n",
    "        best_config_index = df_finding_the_best_configuration['Training IR2'].idxmax()\n",
    "\n",
    "    print(f'The Random Seed Is: {i+best_config_index}')\n",
    "    print(f'The Best Model Configuration Is: {best_config}')\n",
    "    print(f\"Training IR2: {df_all_score[f'id_{i}'][df_all_score[f'id_{i}']['Config']==best_config]['Training IR2'].values}, \\\n",
    "          Validation IR2: {df_all_score[f'id_{i}'][df_all_score[f'id_{i}']['Config']==best_config]['Validation IR2'].values}, \\\n",
    "          Testing IR2: {df_all_score[f'id_{i}'][df_all_score[f'id_{i}']['Config']==best_config]['Testing IR2'].values}\")\n",
    "\n",
    "    # Fit the model on the combined data Train and Val \n",
    "    combined_train_val_X = np.concatenate([train_X, val_X]) \n",
    "    combined_train_val_Y = np.concatenate([train_y, val_Y]) \n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "                                n_estimators = best_config['n_estimators'],\n",
    "                                criterion = best_config['criterion'],\n",
    "                                max_depth = best_config['max_depth'],\n",
    "                                min_samples_split = best_config['min_samples_split'],\n",
    "                                min_samples_leaf = best_config['min_samples_leaf'],\n",
    "                                min_weight_fraction_leaf = best_config['min_weight_fraction_leaf'],\n",
    "                                max_features = best_config['max_features'],\n",
    "                                max_leaf_nodes = best_config['max_leaf_nodes'],\n",
    "                                min_impurity_decrease = best_config['min_impurity_decrease'],\n",
    "                                bootstrap = best_config['bootstrap'],\n",
    "                                oob_score = best_config['oob_score'],\n",
    "                                n_jobs = best_config['n_jobs'],\n",
    "                                random_state = i+best_config_index+digit,\n",
    "                                )\n",
    "    \n",
    "    model.fit(train_X, train_y)\n",
    "\n",
    "    PREDICTIONS = model.predict(test_X)\n",
    "    print(get_eqline_IR2(test_stock_returns, Scaler_Y.inverse_transform(PREDICTIONS)))\n",
    "    ALL_MODEL_PREDICTIONS = np.concatenate((ALL_MODEL_PREDICTIONS, PREDICTIONS))\n",
    "\n",
    "    print(f'ID_{i} - DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting ALL_MODEL_PREDICTIONS to a series and export it to pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(Scaler_Y.inverse_transform(ALL_MODEL_PREDICTIONS.astype(int)), index=df.index[Training_Bars+Validation_Bars+lag:]).to_pickle('./output/RandomForestModel.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Algo_ml_in_finance_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
